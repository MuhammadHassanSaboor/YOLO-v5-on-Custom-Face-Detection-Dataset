{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2DzE9WJCJYo"
      },
      "source": [
        "\n",
        "#Dataset Preparation\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ej0qMeTwHTmK"
      },
      "source": [
        "#Importing Necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVclsTDNHTIK"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mOJCjI7SSFKO"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!cp /content/kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9gdORDwCZBk"
      },
      "source": [
        "#Downloading Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0oRPwNbXSQ0l"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d iamtushara/face-detection-dataset\n",
        "!unzip -q face-detection-dataset.zip -d ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58E0V-AvCbut"
      },
      "source": [
        "#Cloning the YOLO *v5*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wR-01VYXSQxF"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/ultralytics/yolov5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xcugs7CYSQvE"
      },
      "outputs": [],
      "source": [
        "%cd yolov5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qq5fOOhYSQs8"
      },
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rdEpBCSG1AN"
      },
      "source": [
        "#Selecting 1000 images and labels from original dataset for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7opLzgmdGuir"
      },
      "outputs": [],
      "source": [
        "train_images_path = '/content/merged/images/train/'\n",
        "train_labels_path = '/content/merged/labels/train/'\n",
        "val_images_path = '/content/merged/images/validation/'\n",
        "val_labels_path = '/content/merged/labels/validation/'\n",
        "new_dataset_folder = '/content/subset_dataset'\n",
        "\n",
        "# Create a subset folder\n",
        "try:\n",
        "    os.makedirs(new_dataset_folder, exist_ok=True)\n",
        "    os.makedirs(os.path.join(new_dataset_folder, 'images', 'train'), exist_ok=True)\n",
        "    os.makedirs(os.path.join(new_dataset_folder, 'images', 'validation'), exist_ok=True)\n",
        "    os.makedirs(os.path.join(new_dataset_folder, 'labels', 'train'), exist_ok=True)\n",
        "    os.makedirs(os.path.join(new_dataset_folder, 'labels', 'validation'), exist_ok=True)\n",
        "    print(\"Subset folders created successfully.\")\n",
        "except OSError as e:\n",
        "    print(f\"Error: {e}\")\n",
        "\n",
        "# Verify folder creation\n",
        "print(\"New dataset folder structure:\")\n",
        "for root, dirs, files in os.walk(new_dataset_folder):\n",
        "    level = root.replace(new_dataset_folder, '').count(os.sep)\n",
        "    indent = ' ' * 4 * (level)\n",
        "    print('{}{}/'.format(indent, os.path.basename(root)))\n",
        "    subindent = ' ' * 4 * (level + 1)\n",
        "    for file in files:\n",
        "        print('{}{}'.format(subindent, file))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ybQZTvw-L-5N"
      },
      "outputs": [],
      "source": [
        "subset_images_train_path = '/content/subset_dataset/images/train/'\n",
        "subset_images_val_path = '/content/subset_dataset/images/validation/'\n",
        "subset_labels_train_path = '/content/subset_dataset/labels/train/'\n",
        "subset_labels_val_path = '/content/subset_dataset/labels/validation/'\n",
        "\n",
        "# Function to count files in a directory\n",
        "def count_files(directory, extensions):\n",
        "    # List all files in the directory\n",
        "    files = os.listdir(directory)\n",
        "    # Count the number of files with specified extensions\n",
        "    count = sum(1 for file in files if os.path.isfile(os.path.join(directory, file)) and file.lower().endswith(tuple(extensions)))\n",
        "    return count\n",
        "\n",
        "# Count image files in training and validation sets\n",
        "image_extensions = ['.jpg', '.jpeg', '.png', '.gif', '.bmp']  # Add more extensions if needed\n",
        "num_images_train = count_files(subset_images_train_path, image_extensions)\n",
        "num_images_val = count_files(subset_images_val_path, image_extensions)\n",
        "\n",
        "# Count label files in training and validation sets\n",
        "label_extensions = ['.txt']  # Add more extensions if needed\n",
        "num_labels_train = count_files(subset_labels_train_path, label_extensions)\n",
        "num_labels_val = count_files(subset_labels_val_path, label_extensions)\n",
        "\n",
        "# Print counts\n",
        "print(\"Number of image files in the training set:\", num_images_train)\n",
        "print(\"Number of image files in the validation set:\", num_images_val)\n",
        "print(\"Number of label files in the training set:\", num_labels_train)\n",
        "print(\"Number of label files in the validation set:\", num_labels_val)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4238JhXhGgas"
      },
      "source": [
        "##Counting the no of images that we copied in subset folder for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z12ocmhsM22A"
      },
      "outputs": [],
      "source": [
        "subset_images_path = '/content/subset_dataset/train_val/labels/'\n",
        "\n",
        "# List all files in the directory\n",
        "files = os.listdir(subset_images_path)\n",
        "# image_extensions = ['.jpg', '.jpeg', '.png', '.gif', '.bmp']  # Add more extensions if needed\n",
        "image_extensions = ['.txt']  # Add more extensions if needed\n",
        "image_count = sum(1 for file in files if os.path.isfile(os.path.join(subset_images_path, file)) and file.lower().endswith(tuple(image_extensions)))\n",
        "\n",
        "print(\"Number of images:\", image_count)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d9Gjq8_CjdG"
      },
      "source": [
        "#Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4YXI95EUSQrC"
      },
      "outputs": [],
      "source": [
        "!python train.py --weights yolov5s.pt --data /content/dataset.yaml --epochs 20 --batch-size 16 --imgsz 640 --project /content/yolov5/runs/train --name exp_subset --exist-ok --seed 0 --workers 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1KXESY-HBMl"
      },
      "source": [
        "#Visualizing the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLLSnG2gHEcC"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kifoCMSoHEYn"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir /content/yolov5/runs/train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96mQvYZyHJtt"
      },
      "source": [
        "#Testing Part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QbiYl993HEWU"
      },
      "outputs": [],
      "source": [
        "# Model\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n",
        "\n",
        "# Images\n",
        "img = '/content/Shameer_unseen.png'\n",
        "\n",
        "# Inference\n",
        "results = model(img, augment=True)\n",
        "\n",
        "# Results\n",
        "results.print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BSplpUFtHET9"
      },
      "outputs": [],
      "source": [
        "# Model\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n",
        "\n",
        "# Images\n",
        "img = '/content/unseen_image.jpg'\n",
        "\n",
        "# Inference\n",
        "results = model(img, augment=True)\n",
        "\n",
        "# Results\n",
        "results.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff6RrN-PKLEs"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
